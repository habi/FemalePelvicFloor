{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try do do a 3D registration of the pelvic floor scans\n",
    "This notebook is *heavily* based on http://insightsoftwareconsortium.github.io/SimpleITK-Notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "import pandas\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import dask_image.imread\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_scalebar.scalebar import ScaleBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import our own parsing functions which we've added as submodule\n",
    "from BrukerSkyScanLogfileRuminator.parsing_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up figure defaults\n",
    "plt.rc('image', cmap='gray', interpolation='nearest')  # Display all images in b&w and with 'nearest' interpolation\n",
    "plt.rcParams['figure.figsize'] = (16, 9)  # Size up figures a bit\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup scale bar defaults\n",
    "plt.rcParams['scalebar.location'] = 'lower right'\n",
    "plt.rcParams['scalebar.frameon'] = False\n",
    "plt.rcParams['scalebar.color'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Different locations if running either on Linux or Windows\n",
    "FastSSD = False\n",
    "# to speed things up significantly\n",
    "if 'Linux' in platform.system():\n",
    "    if FastSSD:\n",
    "        BasePath = os.path.join(os.sep, 'media', 'habi', 'Fast_SSD')\n",
    "    else:\n",
    "        BasePath = os.path.join(os.sep, 'home', 'habi', 'research-storage-djonov')\n",
    "elif 'Darwin' in platform.system():\n",
    "    # First mount smb://resstore.unibe.ch/ana_rs_djonov/data in the Finder\n",
    "    FastSSD = False\n",
    "    BasePath = os.path.join('/Volumes/data/')\n",
    "elif 'Windows' in platform.system():\n",
    "    if FastSSD:\n",
    "        BasePath = os.path.join('F:\\\\')\n",
    "    else:\n",
    "        if 'anaklin' in platform.node():\n",
    "            BasePath = os.path.join('V:\\\\')\n",
    "        else:\n",
    "            BasePath = os.path.join('V:\\\\')\n",
    "Root = os.path.join(BasePath, 'Aaldijk')\n",
    "print('We are loading all the data from %s' % Root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make us a dataframe for saving all that we need\n",
    "Data = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get *all* log files\n",
    "Data['LogFile'] = [f for f in sorted(glob.glob(os.path.join(Root, '**', '*.log'), recursive=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get *all* log files\n",
    "Data['LogFile'] = [f for f in sorted(glob.glob(os.path.join(Root, '**', '*.log'), recursive=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all folders\n",
    "Data['Folder'] = [os.path.dirname(f) for f in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for samples which are not yet reconstructed\n",
    "for c, row in Data.iterrows():\n",
    "    # Iterate over every 'proj' folder\n",
    "    if 'proj' in row.Folder:\n",
    "        if not 'TScopy' in row.Folder and not 'PR' in row.Folder:\n",
    "            # If there's nothing with 'rec*' on the same level, then tell us        \n",
    "            if not glob.glob(row.Folder.replace('proj', '*rec*')):\n",
    "                print('- %s is missing matching reconstructions' % row.LogFile[len(Root)+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data['XYAlignment'] = [glob.glob(os.path.join(f, '*.csv')) for f in Data['Folder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for samples which are missing the .csv-files for the XY-alignment\n",
    "for c, row in Data.iterrows():\n",
    "    # Iterate over every 'proj' folder\n",
    "    if 'proj' in row.Folder:\n",
    "        if not len(row.XYAlignment):\n",
    "            if not any(x in row.LogFile for x in ['rectmp.log']):\n",
    "                # 'rectmp.log' because we only exclude it afterwards :)\n",
    "                print('- %s has *not* been X/Y aligned' % row.LogFile[len(Root)+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get rid of all logfiles we don't want\n",
    "for c, row in Data.iterrows():\n",
    "    if 'rec' not in row.Folder:  # drop all non-rec folders\n",
    "        Data.drop([c], inplace=True)\n",
    "    elif 'rectmp.log' in row.LogFile:  # drop all temporary logfiles\n",
    "        Data.drop([c], inplace=True)\n",
    "    # elif 'Mouse' in row.LogFile:  # drop scans of Mouse, only register the fetal scans\n",
    "    elif 'Foetus' in row.LogFile:  # drop scans of Fetus, only registers the mouse scans\n",
    "        Data.drop([c], inplace=True)\n",
    "    elif 'cornuta' in row.LogFile:  # drop another scan we did for Dea\n",
    "        Data.drop([c], inplace=True)\n",
    "# Reset dataframe to something that we would get if we only would have loaded the 'rec' files\n",
    "Data = Data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate us some meaningful colums\n",
    "Data['Sample'] = [l[len(Root)+1:].split(os.sep)[0] for l in Data['LogFile']]\n",
    "Data['BaseName'] = [s.split('_')[0] for s in Data['Sample']]\n",
    "Data['Scan'] = ['_'.join(l[len(Root)+1:].split(os.sep)[1:-1]) for l in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the file names of the reconstructions\n",
    "Data['Reconstructions'] = [sorted(glob.glob(os.path.join(f, '*rec0*.png'))) for f in Data['Folder']]\n",
    "Data['Number of reconstructions'] = [len(r) for r in Data.Reconstructions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data['Voxelsize'] = [pixelsize(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data.Voxelsize.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop high-resolution scans, e.g. only register the ones above 12 um\n",
    "Data = Data[Data.Voxelsize > 12]\n",
    "Data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data.Voxelsize.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get out time-scale\n",
    "Data['Scan date'] = [scandate(log) for log in Data['LogFile']]\n",
    "Data['Time passed'] = [sd - Data['Scan date'].min() for sd in Data['Scan date']]\n",
    "Data['Days passed'] = [t.round('d') for t in Data['Time passed']]  # round up or down to day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Zero pad us the day value\n",
    "# We use this later for writing out nice image names\n",
    "Data['Day'] = [str(dp.days).zfill(3) for dp in Data['Days passed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load all reconstructions into ephemereal DASK arrays\n",
    "Reconstructions = [None] * len(Data)\n",
    "for c, row in tqdm(Data.iterrows(),\n",
    "                   desc='Load reconstructions',\n",
    "                   total=len(Data)):\n",
    "    Reconstructions[c] = dask_image.imread.imread(os.path.join(row['Folder'],\n",
    "                                                               '*rec*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How big are the datasets?\n",
    "Data['Size'] = [rec.shape for rec in Reconstructions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[['Sample', 'Scan', 'Size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The three cardinal directions\n",
    "directions = ['Axial',\n",
    "              'Coronal',\n",
    "              'Sagittal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read or calculate the middle slices, put them into the dataframe and save them to disk\n",
    "for d, direction in enumerate(directions):\n",
    "    Data['Mid_' + direction] = [None] * len(Reconstructions)\n",
    "for c, row in tqdm(Data.iterrows(), desc='Middle images', total=len(Data), leave=False):\n",
    "    for d, direction in tqdm(enumerate(directions),\n",
    "                             desc='%s/%s' % (row['Sample'], row['Scan']),\n",
    "                             leave=False,\n",
    "                             total=len(directions)):\n",
    "        outfilepath = os.path.join(os.path.dirname(row['Folder']),\n",
    "                                   '%s.%s.Middle.%s.png' % (row['Sample'],\n",
    "                                                            row['Scan'],\n",
    "                                                            direction))\n",
    "        if os.path.exists(outfilepath):\n",
    "            Data.at[c, 'Mid_' + direction] = dask_image.imread.imread(outfilepath).squeeze()\n",
    "        else:\n",
    "            # Generate requested axial view\n",
    "            if 'Axial' in direction:\n",
    "                Data.at[c, 'Mid_' + direction] = Reconstructions[c][Reconstructions[c].shape[0] // 2].squeeze()\n",
    "            if 'Sagittal' in direction:\n",
    "                Data.at[c, 'Mid_' + direction] = Reconstructions[c][:, Reconstructions[c].shape[1] // 2, :].squeeze()\n",
    "            if 'Coronal' in direction:\n",
    "                Data.at[c, 'Mid_' + direction] = Reconstructions[c][:, :, Reconstructions[c].shape[2] // 2].squeeze()\n",
    "            # Save the calculated 'direction' view to disk           \n",
    "            imageio.imwrite(outfilepath, Data.at[c, 'Mid_' + direction].astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read or calculate the directional MIPs, put them into the dataframe and save them to disk\n",
    "for d, direction in enumerate(directions):\n",
    "    Data['MIP_' + direction] = [None] * len(Reconstructions)\n",
    "for c, row in tqdm(Data.iterrows(), desc='MIPs', total=len(Data), leave=False):\n",
    "    for d, direction in tqdm(enumerate(directions),\n",
    "                             desc='%s/%s' % (row['Sample'], row['Scan']),\n",
    "                             leave=False,\n",
    "                             total=len(directions)):\n",
    "        outfilepath = os.path.join(os.path.dirname(row['Folder']),\n",
    "                                   '%s.%s.MIP.%s.png' % (row['Sample'],\n",
    "                                                      row['Scan'],\n",
    "                                                      direction))\n",
    "        if os.path.exists(outfilepath):\n",
    "            Data.at[c, 'MIP_' + direction] = dask_image.imread.imread(outfilepath).squeeze()\n",
    "        else:\n",
    "            # Generate MIP\n",
    "            Data.at[c, 'MIP_' + direction] = Reconstructions[c].max(axis=d).compute().squeeze()\n",
    "            # Save it out\n",
    "            imageio.imwrite(outfilepath, Data.at[c, 'MIP_' + direction].astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data.BaseName.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Actually start the registration now\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "# from downloaddata import fetch_data as fdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Callback invoked by the interact IPython method for scrolling through the image stacks of\n",
    "# the two images (moving and fixed).\n",
    "def display_images(fixed_image_z, moving_image_z, fixed_npa, moving_npa):\n",
    "    # Create a figure with two subplots and the specified size.\n",
    "    plt.subplots(1, 2, figsize=(10, 8))\n",
    "\n",
    "    # Draw the fixed image in the first subplot.\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(fixed_npa[fixed_image_z, :, :], cmap=plt.cm.Greys_r)\n",
    "    plt.title(\"fixed image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Draw the moving image in the second subplot.\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(moving_npa[moving_image_z, :, :], cmap=plt.cm.Greys_r)\n",
    "    plt.title(\"moving image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Callback invoked by the IPython interact method for scrolling and modifying the alpha blending\n",
    "# of an image stack of two images that occupy the same physical space.\n",
    "def display_images_with_alpha(image_z, alpha, fixed, moving):\n",
    "    img = (1.0 - alpha) * fixed[:, :, image_z] + alpha * moving[:, :, image_z]\n",
    "    plt.imshow(sitk.GetArrayViewFromImage(img), cmap=plt.cm.Greys_r)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Callback invoked when the StartEvent happens, sets up our new data.\n",
    "def start_plot():\n",
    "    global metric_values, multires_iterations\n",
    "\n",
    "    metric_values = []\n",
    "    multires_iterations = []\n",
    "\n",
    "# Callback invoked when the EndEvent happens, do cleanup of data and figure.\n",
    "def end_plot():\n",
    "    global metric_values, multires_iterations\n",
    "\n",
    "    del metric_values\n",
    "    del multires_iterations\n",
    "    # Close figure, we don't want to get a duplicate of the plot latter on.\n",
    "    plt.close()\n",
    "\n",
    "# Callback invoked when the IterationEvent happens, update our data and display new figure.\n",
    "def plot_values(registration_method):\n",
    "    global metric_values, multires_iterations\n",
    "\n",
    "    metric_values.append(registration_method.GetMetricValue())\n",
    "    # Clear the output area (wait=True, to reduce flickering), and plot current data\n",
    "    clear_output(wait=True)\n",
    "    # Plot the similarity metric values\n",
    "    plt.plot(metric_values, \"r\")\n",
    "    plt.plot(\n",
    "        multires_iterations,\n",
    "        [metric_values[index] for index in multires_iterations],\n",
    "        \"b*\",\n",
    "    )\n",
    "    plt.xlabel(\"Iteration Number\", fontsize=12)\n",
    "    plt.ylabel(\"Metric Value\", fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "# Callback invoked when the sitkMultiResolutionIterationEvent happens, update the index into the\n",
    "# metric_values list.\n",
    "def update_multires_iterations():\n",
    "    global metric_values, multires_iterations\n",
    "    multires_iterations.append(len(metric_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data[['Sample', 'Scan date', 'Days passed', 'Day', 'Folder', 'Scan', 'Voxelsize', 'Size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data[['Sample', 'Scan date', 'Days passed', 'Day', 'Folder', 'Scan', 'Voxelsize', 'Size']].to_excel('Tage.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We need to downsample the image to be actually able to register them\n",
    "downsample = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use one scan as fixed image\n",
    "which_fixed = 0\n",
    "fixed_image = sitk.GetImageFromArray(Reconstructions[which_fixed][::downsample,::downsample,::downsample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use another scan as moving image\n",
    "which_moving = 3\n",
    "moving_image = sitk.GetImageFromArray(Reconstructions[which_moving][::downsample,::downsample,::downsample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Registering %s scan on day %s (moving) to day %s (fixed)' % (Data.BaseName.unique()[0], Data.Day[which_moving], Data.Day[which_fixed]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize transformation (as is from SimpleITK notebook)\n",
    "initial_transform = sitk.CenteredTransformInitializer(fixed_image,\n",
    "                                                      moving_image,\n",
    "                                                      sitk.Euler3DTransform(),\n",
    "                                                      sitk.CenteredTransformInitializerFilter.GEOMETRY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copied as is from SimpleITK notebook\n",
    "registration_method = sitk.ImageRegistrationMethod()\n",
    "\n",
    "# Similarity metric settings.\n",
    "registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "registration_method.SetMetricSamplingPercentage(0.01)\n",
    "\n",
    "registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "\n",
    "# Optimizer settings.\n",
    "registration_method.SetOptimizerAsGradientDescent(\n",
    "    learningRate=1.0,\n",
    "    numberOfIterations=100,\n",
    "    convergenceMinimumValue=1e-6,\n",
    "    convergenceWindowSize=10,\n",
    ")\n",
    "registration_method.SetOptimizerScalesFromPhysicalShift()\n",
    "\n",
    "# Setup for the multi-resolution framework.\n",
    "registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[4, 2, 1])\n",
    "registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[2, 1, 0])\n",
    "registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "\n",
    "# Don't optimize in-place, we would possibly like to run this cell multiple times.\n",
    "registration_method.SetInitialTransform(initial_transform, inPlace=False)\n",
    "\n",
    "# Connect all of the observers so that we can perform plotting during registration.\n",
    "registration_method.AddCommand(sitk.sitkStartEvent, start_plot)\n",
    "registration_method.AddCommand(sitk.sitkEndEvent, end_plot)\n",
    "registration_method.AddCommand(sitk.sitkMultiResolutionIterationEvent, update_multires_iterations)\n",
    "registration_method.AddCommand(sitk.sitkIterationEvent, lambda: plot_values(registration_method))\n",
    "\n",
    "final_transform = registration_method.Execute(sitk.Cast(fixed_image,\n",
    "                                                        sitk.sitkFloat32),\n",
    "                                              sitk.Cast(moving_image,\n",
    "                                                        sitk.sitkFloat32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Final metric value: {registration_method.GetMetricValue()}\")\n",
    "print(f\"Optimizer's stopping condition, {registration_method.GetOptimizerStopConditionDescription()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We should probably save the transformation somewhere\n",
    "print(final_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resample image\n",
    "moving_resampled = sitk.Resample(moving_image,\n",
    "                                 fixed_image,\n",
    "                                 final_transform,\n",
    "                                 sitk.sitkLinear,\n",
    "                                 0.0,\n",
    "                                 moving_image.GetPixelID())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save out registered image\n",
    "moving_resampled_filename = os.path.join(os.path.dirname(Data.Folder[which_moving]),\n",
    "                                         '%s.registered_with.%s.downsampled_%sx.tif' % (Data.Sample[which_moving],\n",
    "                                                                                        Data.Sample[which_fixed],\n",
    "                                                                                        downsample))\n",
    "if not os.path.exists(moving_resampled_filename):\n",
    "    print('Saving registered image to %s' % moving_resampled_filename)\n",
    "    sitk.WriteImage(moving_resampled, moving_resampled_filename)\n",
    "else:\n",
    "    print('Already written to %s' % moving_resampled_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save fixed image, resampled\n",
    "fixed_resampled_filename = os.path.join(os.path.dirname(Data.Folder[which_fixed]),\n",
    "                                        '%s.downsampled.%sx.tif' % (Data.Sample[which_fixed],\n",
    "                                                                    downsample))\n",
    "if not os.path.exists(fixed_resampled_filename):\n",
    "    print('Saving resampled fixed image to %s' % fixed_resampled_filename[len(Root):])        \n",
    "    sitk.WriteImage(fixed_image, fixed_resampled_filename)\n",
    "else:\n",
    "    print('Already written to %s' % fixed_resampled_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read images in again\n",
    "img_fixed = dask_image.imread.imread(fixed_resampled_filename)\n",
    "img_registered = dask_image.imread.imread(moving_resampled_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show what we did there\n",
    "plt.subplot(221)\n",
    "plt.imshow(img_fixed[img_fixed.shape[0]//2])\n",
    "plt.title('%s, %sx downsampled, middle slice' % (Data.Sample[which_fixed], downsample))\n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'][which_fixed]*downsample,'um'))\n",
    "plt.axis('off')\n",
    "plt.subplot(222)\n",
    "plt.imshow(img_registered[img_registered.shape[0]//2])\n",
    "plt.title('%s, %sx downsampled, registered' % (Data.Sample[which_moving], downsample))\n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'][which_moving]*downsample,'um'))\n",
    "plt.axis('off')\n",
    "plt.subplot(223)\n",
    "plt.imshow(Reconstructions[which_moving][::downsample,::downsample,::downsample][Reconstructions[which_fixed][::downsample,::downsample,::downsample].shape[0]//2])\n",
    "plt.title('%s, %x downsampled original' % (Data.Sample[which_moving], downsample))\n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'][which_moving]*downsample,'um'))\n",
    "plt.axis('off')\n",
    "plt.subplot(224)\n",
    "plt.imshow(img_fixed[img_fixed.shape[0]//2], alpha=0.5)\n",
    "plt.imshow(img_registered[img_registered.shape[0]//2], alpha=0.5, cmap='viridis')\n",
    "plt.title('Overlay of fixed and registered slice')\n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'][which_moving]*downsample,'um'))\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(os.path.dirname(Data.Folder[which_moving]),\n",
    "                         'Registration.%s.downsampled.%sx.day.%s.with.day.%s.png' % (Data['BaseName'].unique()[0],\n",
    "                                                                                     downsample,\n",
    "                                                                                     Data['Day'][which_moving],\n",
    "                                                                                     Data['Day'][which_fixed])),\n",
    "            transparent=False,\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def registration(which_fixed, which_moving, downsample=4, verbose=False):\n",
    "    '''Collect all the stuff above into one function, facilitating usage'''\n",
    "    # First let's see if we already wrote out the file, then do *not* do this\n",
    "    outputname = os.path.join(os.path.dirname(Data.Folder[which_moving]),\n",
    "                              'Registration.%s.downsampled.%sx.day.%s.to.day.%s.png' % (Data['BaseName'].unique()[0],\n",
    "                                                                                        downsample,\n",
    "                                                                                        Data['Day'][which_moving],\n",
    "                                                                                        Data['Day'][which_fixed]))\n",
    "\n",
    "    if os.path.exists(outputname):\n",
    "        print('Already ran registration and saved output to %s' % outputname)\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('Registering %s day %s (moving) to day %s (fixed)' % (Data.BaseName.unique()[0],\n",
    "                                                                        Data['Days passed'][which_moving].days,\n",
    "                                                                        Data['Days passed'][which_fixed].days))\n",
    "        # Load images\n",
    "        fixed_image = sitk.GetImageFromArray(Reconstructions[which_fixed][::downsample,::downsample,::downsample])    \n",
    "        moving_image = sitk.GetImageFromArray(Reconstructions[which_moving][::downsample,::downsample,::downsample])\n",
    "        # Initialize transformation (as is from SimpleITK notebook)\n",
    "        initial_transform = sitk.CenteredTransformInitializer(fixed_image,\n",
    "                                                              moving_image,\n",
    "                                                              sitk.Euler3DTransform(),\n",
    "                                                              sitk.CenteredTransformInitializerFilter.GEOMETRY)\n",
    "        # Copied as is from SimpleITK notebook\n",
    "        registration_method = sitk.ImageRegistrationMethod()\n",
    "        # Similarity metric settings.\n",
    "        registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "        registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "        registration_method.SetMetricSamplingPercentage(0.01)\n",
    "        registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "        # Optimizer settings.\n",
    "        registration_method.SetOptimizerAsGradientDescent(\n",
    "            learningRate=1.0,\n",
    "            numberOfIterations=100,\n",
    "            convergenceMinimumValue=1e-6,\n",
    "            convergenceWindowSize=10,\n",
    "        )\n",
    "        registration_method.SetOptimizerScalesFromPhysicalShift()\n",
    "        # Setup for the multi-resolution framework.\n",
    "        registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[4, 2, 1])\n",
    "        registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[2, 1, 0])\n",
    "        registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "        # Don't optimize in-place, we would possibly like to run this cell multiple times.\n",
    "        registration_method.SetInitialTransform(initial_transform, inPlace=False)\n",
    "        if verbose:\n",
    "            # Connect all of the observers so that we can perform plotting during registration.\n",
    "            registration_method.AddCommand(sitk.sitkStartEvent, start_plot)\n",
    "            registration_method.AddCommand(sitk.sitkEndEvent, end_plot)\n",
    "            registration_method.AddCommand(sitk.sitkMultiResolutionIterationEvent, update_multires_iterations)\n",
    "            registration_method.AddCommand(sitk.sitkIterationEvent, lambda: plot_values(registration_method))\n",
    "        final_transform = registration_method.Execute(sitk.Cast(fixed_image,\n",
    "                                                                sitk.sitkFloat32),\n",
    "                                                      sitk.Cast(moving_image,\n",
    "                                                                sitk.sitkFloat32))\n",
    "        # We should probably save the transformation somewhere\n",
    "        # print(final_transform)    \n",
    "        # Resample image\n",
    "        moving_resampled = sitk.Resample(moving_image,\n",
    "                                         fixed_image,\n",
    "                                         final_transform,\n",
    "                                         sitk.sitkLinear,\n",
    "                                         0.0,\n",
    "                                         moving_image.GetPixelID())\n",
    "        # Save out registered moving image\n",
    "        moving_resampled_filename = os.path.join(os.path.dirname(Data.Folder[which_moving]),\n",
    "                                                 '%s.registered_to.%s.downsampled_%sx.tif' % (Data.Sample[which_moving],\n",
    "                                                                                              Data.Sample[which_fixed],\n",
    "                                                                                              downsample))\n",
    "        if not os.path.exists(moving_resampled_filename):\n",
    "            if verbose:\n",
    "                print('Saving registered moving image to %s' % moving_resampled_filename)\n",
    "            sitk.WriteImage(moving_resampled, moving_resampled_filename)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('Already written to %s' % moving_resampled_filename)\n",
    "        fixed_resampled_filename = os.path.join(os.path.dirname(Data.Folder[which_fixed]),\n",
    "                                                '%s.downsampled.%sx.tif' % (Data.Sample[which_fixed],\n",
    "                                                                            downsample))\n",
    "        if not os.path.exists(fixed_resampled_filename):\n",
    "            if verbose:\n",
    "                print('Saving downsampled fixed image to %s' % fixed_resampled_filename[len(Root):])        \n",
    "            sitk.WriteImage(fixed_image, fixed_resampled_filename)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('Already written to %s' % fixed_resampled_filename)\n",
    "        # Read images in again\n",
    "        img_fixed = dask_image.imread.imread(fixed_resampled_filename)\n",
    "        # print(img_fixed.shape)    \n",
    "        img_moving = dask_image.imread.imread(moving_resampled_filename)        \n",
    "        # print(img_moving.shape)\n",
    "        # Show what we did there\n",
    "        # https://scikit-image.org/docs/stable/auto_examples/applications/plot_image_comparison.html\n",
    "        plt.subplot(221)\n",
    "        plt.imshow(img_fixed[img_fixed.shape[0]//2])\n",
    "        plt.title('Fixed: %s@day %s\\n%sx downsampled, middle slice' % (Data.BaseName[which_fixed],\n",
    "                                                                       Data['Days passed'][which_fixed].days,\n",
    "                                                                       downsample))\n",
    "        plt.gca().add_artist(ScaleBar(Data['Voxelsize'][which_fixed]*downsample,'um'))\n",
    "        plt.axis('off')\n",
    "        plt.subplot(222)\n",
    "        plt.imshow(img_moving[img_moving.shape[0]//2])\n",
    "        plt.title('Moving: %s@day %s\\n%sx downsampled, registered' % (Data.BaseName[which_moving],\n",
    "                                                                      Data['Days passed'][which_moving].days,\n",
    "                                                                      downsample))        \n",
    "        plt.gca().add_artist(ScaleBar(Data['Voxelsize'][which_moving]*downsample,'um'))\n",
    "        plt.axis('off')\n",
    "        plt.subplot(234)\n",
    "        plt.imshow(skimage.util.compare_images(img_fixed[img_fixed.shape[0]//2],\n",
    "                                               img_moving[img_moving.shape[0]//2],\n",
    "                                               method='checkerboard'))\n",
    "        plt.title('Checkerboard of fixed and moving images')\n",
    "        plt.gca().add_artist(ScaleBar(Data['Voxelsize'][which_moving]*downsample,'um'))\n",
    "        plt.axis('off')\n",
    "        plt.subplot(235)\n",
    "        plt.imshow(skimage.util.compare_images(img_fixed[img_fixed.shape[0]//2],\n",
    "                                               img_moving[img_moving.shape[0]//2],\n",
    "                                               method='diff'))\n",
    "        plt.title('Diff of fixed and moving images')\n",
    "        plt.gca().add_artist(ScaleBar(Data['Voxelsize'][which_moving]*downsample,'um'))\n",
    "        plt.axis('off')\n",
    "        plt.subplot(236)\n",
    "        plt.imshow(skimage.util.compare_images(img_fixed[img_fixed.shape[0]//2],\n",
    "                                               img_moving[img_moving.shape[0]//2],\n",
    "                                               method='blend'))\n",
    "        plt.title('Blend of fixed and moving images')\n",
    "        plt.gca().add_artist(ScaleBar(Data['Voxelsize'][which_moving]*downsample,'um'))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        if verbose:\n",
    "            print('Saving result image to %s' % outputname)\n",
    "        plt.savefig(outputname,\n",
    "                    transparent=False,\n",
    "                    bbox_inches='tight')\n",
    "        plt.show()\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "registration(0, 5,\n",
    "             downsample=10,\n",
    "             verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use\n",
    "`convert -delay 50 -dispose previous */*Reg*.to.day.000.png Registration.to.day.000.gif`\n",
    "to generate a GIF movie.\n",
    "\n",
    "(`-dispose previous` is taken from https://webinista.com/updates/how-to-create-animated-gifs-imagemagick/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fixed in tqdm(range(len(Data)),\n",
    "                  desc='Registration'):\n",
    "# # for fixed in [0,1]:\n",
    "    for moving in tqdm(range(len(Data)),\n",
    "                       desc='Registration',\n",
    "                       leave=False):\n",
    "        registration(fixed, moving, downsample=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
