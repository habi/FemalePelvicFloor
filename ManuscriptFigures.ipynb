{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the figures for the manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "import glob\n",
    "import pandas\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask_image.imread\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn\n",
    "import numpy\n",
    "from tqdm.auto import tqdm, trange\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import our own parsing functions which we've added as submodule\n",
    "from BrukerSkyScanLogfileRuminator.parsing_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set dask temporary folder\n",
    "# Do this before creating a client: https://stackoverflow.com/a/62804525/323100\n",
    "import tempfile\n",
    "if 'Linux' in platform.system():\n",
    "    tmp = os.path.join(os.sep, 'media', 'habi', 'Fast_SSD')\n",
    "elif 'Darwin' in platform.system():\n",
    "    tmp = tempfile.gettempdir()\n",
    "else:\n",
    "    if 'anaklin' in platform.node():\n",
    "        tmp = os.path.join('F:\\\\')\n",
    "    else:\n",
    "        tmp = os.path.join('D:\\\\')\n",
    "dask.config.set({'temporary_directory': os.path.join(tmp, 'tmp')})\n",
    "print('Dask temporary files go to %s' % dask.config.get('temporary_directory'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start cluster and client now, after setting tempdir\n",
    "try:\n",
    "    cluster = LocalCluster()\n",
    "except PermissionError:\n",
    "    print('Mount the Fast_SSD, otherwise we cannot use it for saving the temporary files!')\n",
    "    print('Then rerun this cell.')\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('You can seee what DASK is doing at \"http://localhost:%s/status\"' % client.scheduler_info()['services']['dashboard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Ignore warnings in the notebook\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up figure defaults\n",
    "plt.rc('image', cmap='gray', interpolation='nearest')  # Display all images in b&w and with 'nearest' interpolation\n",
    "plt.rcParams['figure.figsize'] = (16, 9)  # Size up figures a bit\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup scale bar defaults\n",
    "plt.rcParams['scalebar.location'] = 'lower right'\n",
    "plt.rcParams['scalebar.frameon'] = False\n",
    "plt.rcParams['scalebar.color'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seaborn context\n",
    "# context: one of {paper, notebook, talk, poster}\n",
    "seaborn.set_context('paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Different locations if running either on Linux or Windows\n",
    "FastSSD = True\n",
    "# to speed things up significantly\n",
    "if 'Linux' in platform.system():\n",
    "    if FastSSD:\n",
    "        BasePath = os.path.join(os.sep, 'media', 'habi', 'Fast_SSD')\n",
    "    else:\n",
    "        BasePath = os.path.join(os.sep, 'home', 'habi', 'research-storage-djonov')\n",
    "elif 'Darwin' in platform.system():\n",
    "    # First mount smb://resstore.unibe.ch/ana_rs_djonov/data in the Finder\n",
    "    FastSSD = False\n",
    "    BasePath = os.path.join('/Volumes/data/')\n",
    "elif 'Windows' in platform.system():\n",
    "    if FastSSD:\n",
    "        BasePath = os.path.join('F:\\\\')\n",
    "    else:\n",
    "        if 'anaklin' in platform.node():\n",
    "            BasePath = os.path.join('V:\\\\')\n",
    "        else:\n",
    "            BasePath = os.path.join('V:\\\\')\n",
    "Root = os.path.join(BasePath, 'Aaldijk')\n",
    "print('We are loading all the data from %s' % Root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_git_hash():\n",
    "    '''\n",
    "    Get the current git hash from the repository.\n",
    "    Based on http://stackoverflow.com/a/949391/323100 and\n",
    "    http://stackoverflow.com/a/18283905/323100\n",
    "    '''\n",
    "    from subprocess import Popen, PIPE\n",
    "    import os\n",
    "    gitprocess = Popen(['git',\n",
    "                        '--git-dir',\n",
    "                        os.path.join(os.getcwd(), '.git'),\n",
    "                        'rev-parse',\n",
    "                        '--short',\n",
    "                        '--verify',\n",
    "                        'HEAD'],\n",
    "                       stdout=PIPE)\n",
    "    (output, _) = gitprocess.communicate()\n",
    "    return output.strip().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make directory for output\n",
    "OutPutDir = os.path.join(os.getcwd(), 'Output', get_git_hash())\n",
    "print('We are saving all the output to %s' % OutPutDir)\n",
    "os.makedirs(OutPutDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make us a dataframe for saving all that we need\n",
    "Data = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get *all* log files, unsorted but faster than with glob\n",
    "print('Searching for all log files in %s' % Root)\n",
    "Data['LogFile'] = [os.path.join(root, name)\n",
    "                   for root, dirs, files in os.walk(Root)\n",
    "                   for name in files\n",
    "                   if name.endswith((\".log\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop all non-mouse scans\n",
    "for c, row in Data.iterrows():\n",
    "    if 'Foetus02' not in row.LogFile:\n",
    "        Data.drop([c], inplace=True)\n",
    "Data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get all folders\n",
    "Data['Folder'] = [os.path.dirname(f) for f in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get rid of all logfiles that we don't want and need\n",
    "for c, row in Data.iterrows():\n",
    "    if 'rec' not in row.Folder:  # drop all non-rec folders\n",
    "        Data.drop([c], inplace=True)\n",
    "    elif 'SubScan' in row.Folder:  # drop all partial reconstructions which might be there from synchronization\n",
    "        Data.drop([c], inplace=True)        \n",
    "    elif 'rectmp.log' in row.LogFile:  # drop all temporary logfiles\n",
    "        Data.drop([c], inplace=True)\n",
    "# Reset dataframe to something that we would get if we only would have loaded the 'rec' files\n",
    "Data = Data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate us some meaningful colums\n",
    "Data['Sample'] = [l[len(Root)+1:].split(os.sep)[0] for l in Data['LogFile']]\n",
    "Data['SampleName'] = [sn.split('_')[0] for sn in Data['Sample']]\n",
    "Data['Scan'] = ['_'.join(l[len(Root)+1:].split(os.sep)[1:-1]) for l in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the file names of the reconstructions\n",
    "Data['Reconstructions'] = [sorted(glob.glob(os.path.join(f, '*rec0*.png'))) for f in Data['Folder']]\n",
    "Data['Number of reconstructions'] = [len(r) for r in Data.Reconstructions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop samples which have either not been reconstructed yet or of which we deleted the reconstructions with\n",
    "# `find . -name \"*rec*.png\" -type f -mtime +333 -delete`\n",
    "# Based on https://stackoverflow.com/a/13851602\n",
    "# for c,row in Data.iterrows():\n",
    "#     if not row['Number of reconstructions']:\n",
    "#         print('%s contains no PNG files, we might be currently reconstructing it' % row.Folder)\n",
    "Data = Data[Data['Number of reconstructions'] > 0]\n",
    "Data.reset_index(drop=True, inplace=True)\n",
    "print('We have %s folders with reconstructions' % (len(Data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get scanning parameters to doublecheck from logfiles\n",
    "Data['Scanner'] = [scanner(log) for log in Data['LogFile']]\n",
    "Data['Voltage'] = [voltage(log) for log in Data['LogFile']]\n",
    "Data['Current'] = [current(log) for log in Data['LogFile']]\n",
    "Data['Voxelsize'] = [pixelsize(log, rounded=True) for log in Data['LogFile']]\n",
    "Data['CameraWindow'] = [projection_size(log) for log in Data['LogFile']]\n",
    "Data['Exposuretime'] = [exposure(log) for log in Data['LogFile']]\n",
    "Data['Averaging'] = [averaging(log) for log in Data['LogFile']]\n",
    "Data['Stacks'] = [stacks(log) for log in Data['LogFile']]\n",
    "Data['RotationStep'] = [rotationstep(log) for log in Data['LogFile']]\n",
    "Data['Scan date'] = [scandate(log) for log in Data['LogFile']]\n",
    "Data['Scan time'] = [duration(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort our dataframe by scan date\n",
    "Data.sort_values(by='Scan date', inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get reconstruction parameters to doublecheck from logfiles\n",
    "Data['Grayvalue'] = [reconstruction_grayvalue(log) for log in Data['LogFile']]\n",
    "Data['RingartefactCorrection'] = [ringremoval(log) for log in Data['LogFile']]\n",
    "Data['BeamHardeningCorrection'] = [beamhardening(log) for log in Data['LogFile']]\n",
    "Data['DefectPixelMasking'] = [defectpixelmasking(log) for log in Data['LogFile']]\n",
    "Data['ROI'] = [region_of_interest(log) for log in Data['LogFile']]\n",
    "Data['Rot'] = [crosssection_rotation(l) for l in Data.LogFile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate time 'spent' since start\n",
    "Data['Time passed'] = [sd - Data['Scan date'].min() for sd in Data['Scan date']]\n",
    "# Also extract days, rounded\n",
    "Data['Days passed'] = [t.round('d') for t in Data['Time passed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load all reconstructions into ephemereal DASK arrays\n",
    "Reconstructions = [None] * len(Data)\n",
    "for c, row in tqdm(Data.iterrows(),\n",
    "                   desc='Load reconstructions',\n",
    "                   total=len(Data)):\n",
    "    Reconstructions[c] = dask_image.imread.imread(os.path.join(row['Folder'],\n",
    "                                                               '*rec*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How big are the datasets?\n",
    "Data['Size'] = [rec.shape for rec in Reconstructions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean brightness of the reconstructions\n",
    "# Subsample for speed reasons\n",
    "subsample = 5\n",
    "Data['MeanBrightness'] = [rec[::subsample,::subsample,::subsample].mean().compute() for rec in Reconstructions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Data[['Sample', 'Scan', 'Size', 'ROI', 'Days passed', 'Grayvalue', 'RingartefactCorrection', 'BeamHardeningCorrection', 'DefectPixelMasking', 'Rot', 'Grayvalue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The three cardinal directions\n",
    "directions = ['Axial',\n",
    "              'Coronal',\n",
    "              'Sagittal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read or calculate the middle slices, put them into the dataframe and save them to disk\n",
    "for d, direction in enumerate(directions):\n",
    "    Data['Mid_' + direction] = [None] * len(Reconstructions)\n",
    "for c, row in tqdm(Data.iterrows(), desc='Middle images', total=len(Data), leave=False):\n",
    "    for d, direction in tqdm(enumerate(directions),\n",
    "                             desc='%s/%s' % (row['Sample'], row['Scan']),\n",
    "                             leave=False,\n",
    "                             total=len(directions)):\n",
    "        outfilepath = os.path.join(os.path.dirname(row['Folder']),\n",
    "                                   '%s.%s.Middle.%s.png' % (row['Sample'],\n",
    "                                                            row['Scan'],\n",
    "                                                            direction))\n",
    "        if os.path.exists(outfilepath):\n",
    "            Data.at[c, 'Mid_' + direction] = dask_image.imread.imread(outfilepath).squeeze()\n",
    "        else:\n",
    "            # Generate requested axial view\n",
    "            if 'Axial' in direction:\n",
    "                Data.at[c, 'Mid_' + direction] = Reconstructions[c][Data['Size'][c][0] // 2].compute().squeeze()\n",
    "            if 'Coronal' in direction:\n",
    "                Data.at[c, 'Mid_' + direction] = Reconstructions[c][:, Data['Size'][c][1] // 2, :].compute().squeeze()\n",
    "            if 'Sagittal' in direction:\n",
    "                Data.at[c, 'Mid_' + direction] = Reconstructions[c][:, :, Data['Size'][c][2] // 2].compute().squeeze()\n",
    "            # Save the calculated 'direction' view to disk\n",
    "            imageio.imwrite(outfilepath, (Data.at[c, 'Mid_' + direction]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read or calculate the directional MIPs, put them into the dataframe and save them to disk\n",
    "for d, direction in enumerate(directions):\n",
    "    Data['MIP_' + direction] = [None] * len(Reconstructions)\n",
    "for c, row in tqdm(Data.iterrows(), desc='MIPs', total=len(Data), leave=False):\n",
    "    for d, direction in tqdm(enumerate(directions),\n",
    "                             desc='%s/%s' % (row['Sample'], row['Scan']),\n",
    "                             leave=False,\n",
    "                             total=len(directions)):\n",
    "        outfilepath = os.path.join(os.path.dirname(row['Folder']),\n",
    "                                   '%s.%s.MIP.%s.png' % (row['Sample'],\n",
    "                                                      row['Scan'],\n",
    "                                                      direction))\n",
    "        if os.path.exists(outfilepath):\n",
    "            Data.at[c, 'MIP_' + direction] = dask_image.imread.imread(outfilepath).squeeze()\n",
    "        else:\n",
    "            # Generate MIP\n",
    "            Data.at[c, 'MIP_' + direction] = Reconstructions[c].max(axis=d).compute().squeeze()\n",
    "            # Save it out\n",
    "            imageio.imwrite(outfilepath, Data.at[c, 'MIP_' + direction].astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define us some helper functions for the figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from AcinarSize_Johannes/MicroscopyFigure.ipynb\n",
    "def label_image(image, labeltext, x=None, y=None, color='white', boxcolor=None):\n",
    "    '''We have to print a label over the image several times'''\n",
    "    # If we didn't set coordinates, then use defaults\n",
    "    if not x:\n",
    "        x=numpy.shape(image)[1] * 0.0309\n",
    "    if not y:\n",
    "        y=numpy.shape(image)[0] - (numpy.shape(image)[0] * 0.0309)\n",
    "    t = plt.gca().text(x,\n",
    "                       y,\n",
    "                       labeltext,\n",
    "                       color=color,\n",
    "                       fontsize=12,\n",
    "                       verticalalignment='center',\n",
    "                       horizontalalignment='center')\n",
    "    if boxcolor is not None:\n",
    "        t.set_bbox(dict(facecolor=boxcolor,\n",
    "                        edgecolor=boxcolor,\n",
    "                        alpha=0.618))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markregion(image, coordinates, width, height, showimage=True):\n",
    "    \"\"\"Mark a rectancular region in an image\"\"\"\n",
    "    from matplotlib.patches import Rectangle\n",
    "    if showimage:\n",
    "        plt.imshow(image)    \n",
    "    # Mark center\n",
    "    plt.scatter(coordinates[0], coordinates[1], color=seaborn.color_palette()[0], marker='x')\n",
    "    # Draw rectangle\n",
    "    plt.gca().add_patch(Rectangle((coordinates[0] - width / 2, coordinates[1] - height / 2), width, height,\n",
    "                                  # edgecolor=seaborn.color_palette()[0],\n",
    "                                  edgecolor='white',\n",
    "                                  linestyle='--',\n",
    "                                  facecolor='none'))\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(stack, coordinates, width=None, height=None, verbose=False):\n",
    "    \"\"\"Get a (small) region from a stack\"\"\"\n",
    "    extract=stack[coordinates[2]][coordinates[1] - int(height/2):coordinates[1] + int(height/2),coordinates[0] - int(width/2):coordinates[0]+int(width/2)]\n",
    "    if verbose:\n",
    "        fig = plt.subplot(121)\n",
    "        # plt.imshow(stack[coordinates[2]])\n",
    "        # show region mark\n",
    "        markregion(stack[coordinates[2]], coordinates, width, height, showimage=True)\n",
    "        plt.title('Slice %s of input stack\\n'\n",
    "                  'Centered at x=%s and y=%s' % (coordinates[2], coordinates[0], coordinates[1]))\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(extract)\n",
    "        plt.title('Extract\\n'\n",
    "                 '%s x %s px' % (extract.shape[0], extract.shape[1]))\n",
    "        plt.show()\n",
    "    return(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract(Reconstructions[0],\n",
    "        (800, 900, 1634),\n",
    "        width=1200, height=750,\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Figure 1\n",
    "\n",
    "We want to show a figure with the gray value curve along the timeframe we stained and scanned.\n",
    "In addition some representative slices of a dataset at the start, middle and end of the duration.\n",
    "And some detailed view of marked regions in these slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically find the one day closest to the middle of the duration.\n",
    "# https://stackoverflow.com/a/30112305/323100\n",
    "middleone = Data.index[(Data['Days passed'] - Data['Days passed'].mean()).abs().argsort()[:1]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put coordinates we want to show into dataframe\n",
    "Data['Coordinates'] = ''\n",
    "Data.at[0, 'Coordinates'] = [800, 900, 1634]\n",
    "Data.at[middleone, 'Coordinates'] = [800, 900, 1634]\n",
    "Data.at[len(Data)-1, 'Coordinates'] = [1000, 1500, 2614]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[['Sample', 'Scan', 'Voxelsize', 'Coordinates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11.0/20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant regions from relevant images\n",
    "width = 1000\n",
    "height = 750\n",
    "detail_start = extract(Reconstructions[0],\n",
    "                       Data['Coordinates'][0],\n",
    "                       width=width, height=height, verbose=True)\n",
    "detail_mid = extract(Reconstructions[middleone],\n",
    "                     Data['Coordinates'][middleone], \n",
    "                     width=width, height=height, verbose=True)\n",
    "# Scale width/height with voxel size difference (11/20 um)\n",
    "detail_end = extract(Reconstructions[-1],\n",
    "                     Data['Coordinates'].iloc[-1], width=width/.55, height=height/.55, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig. 1: A) Detail of a native scan of the human foetal pelvis, the ossification centres of the iliac bone (bottom) and two ossification centres of the sacrum (top left and right) can be seen. The soft tissue is not distinguishable. B) The same detail after 158 days of Lugol immersion. Besides the bony structures, now the cartilage, muscles, blood vessels and connective tissue can be distinguished. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean brightness of the scan with their dates\n",
    "seaborn.scatterplot(data=Data,\n",
    "                    x='Scan date',\n",
    "                    y='MeanBrightness',\n",
    "                    # size='MeanBrightness'\n",
    "                   )\n",
    "# Label text: https://matplotlib.org/stable/tutorials/text/annotations.html\n",
    "for c,row in Data.iterrows():\n",
    "    plt.gca().annotate(row.Sample.replace('Foetus01', 'F1').replace('_Lugol','').replace('_05pct','').replace('_10pct','').replace('_15pct',''),\n",
    "                       xy=(row['Scan date'], row.MeanBrightness),\n",
    "                       xycoords='data',\n",
    "                       xytext=(-3, -75),\n",
    "                       textcoords='offset points',\n",
    "                       ha='left',\n",
    "                       rotation=-60)\n",
    "plt.ylim(ymin=0)\n",
    "plt.title('Average gray value of the %s-times subsampled reconstructions' % subsample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate figure 1\n",
    "\n",
    "plt.subplot(311)\n",
    "# Plot the mean brightness of the scan with their dates\n",
    "seaborn.lineplot(data=Data,\n",
    "                 x='Scan date',\n",
    "                 y='MeanBrightness',\n",
    "                 # size='MeanBrightness'\n",
    "                   )\n",
    "# Label text: https://matplotlib.org/stable/tutorials/text/annotations.html\n",
    "for c,row in Data.iterrows():\n",
    "    plt.gca().annotate(row.Sample.replace('Foetus01', 'F1').replace('_Lugol','').replace('_05pct','').replace('_10pct','').replace('_15pct',''),\n",
    "                       xy=(row['Scan date'], row.MeanBrightness),\n",
    "                       xycoords='data',\n",
    "                       xytext=(-3, -75),\n",
    "                       textcoords='offset points',\n",
    "                       ha='left',\n",
    "                       rotation=-60)\n",
    "from string import ascii_uppercase    \n",
    "for c, i in enumerate([0, middleone, len(Data)-1]):\n",
    "    plt.gca().annotate('%s/%s' % (ascii_uppercase[c+1],ascii_uppercase[c+1+3]),\n",
    "                       xy = (Data['Scan date'][i], Data['MeanBrightness'][i]),\n",
    "                       xycoords='data',\n",
    "                       color='red')\n",
    "plt.ylim(ymin=0)\n",
    "plt.title('Average gray value of the %s-times subsampled reconstructions' % subsample)\n",
    "\n",
    "plt.subplot(334)\n",
    "markregion(Reconstructions[0][Data['Coordinates'][0][2]], \n",
    "           Data['Coordinates'][0], width, height)\n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'][0],'um'))\n",
    "label_image(Reconstructions[0][Data['Coordinates'][0][2]], 'B')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(335)\n",
    "markregion(Reconstructions[middleone][Data['Coordinates'][middleone][2]],\n",
    "           Data['Coordinates'][middleone], width, height)\n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'][middleone],'um'))\n",
    "label_image(Reconstructions[middleone][Data['Coordinates'][middleone][2]], 'C')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(336)\n",
    "markregion(Reconstructions[-1][Data['Coordinates'].iloc[-1][2]],\n",
    "           Data['Coordinates'].iloc[-1],\n",
    "           width=width/.55, height=height/.55)\n",
    "           \n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'].iloc[-1],'um'))\n",
    "label_image(Reconstructions[-1][Data['Coordinates'].iloc[-1][2]], 'D')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(337)\n",
    "plt.imshow(detail_start)\n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'][0],'um'))\n",
    "label_image(detail_start, 'E')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(338)\n",
    "plt.imshow(detail_mid)\n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'][middleone],'um'))\n",
    "label_image(detail_mid, 'F')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(339)\n",
    "plt.imshow(detail_end)\n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'].iloc[-1],'um'))\n",
    "label_image(detail_end, 'G')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(OutPutDir, 'Fig01.png'),\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Figure 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig. 2: Details of different anatomical structures in the human pelvis, seen after 158 days of Lugol immersion. A) Greater vestibular glands on both sides of the vulvar vestibule. B) Uterus (bottom of the image) and several cuts through the left fallopian tube, parts of the ovary are also visible. C) Muscle layers of the distal rectum with circular and longitudinally oriented muscle fibre bundles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Koordinaten (in 11um stack 152d)\n",
    "\n",
    "A) x: 2249, y: 1075, z:819 --> war gedreht, jetzt 1936,2218,819\n",
    "\n",
    "B) x:2223 y: 1308 z:2527 --> war gedreht, jetzt 2230,2093,2527\n",
    "\n",
    "C) x: 1939, y: 1063, z: 819 --> war gedreht, jetzt 2061,1878,819"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect figure 2\n",
    "\n",
    "plt.subplot(231)\n",
    "markregion(Reconstructions[-1][819], \n",
    "           (1936, 2218, 819), 500, 500)\n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'].iloc[-1],'um'))\n",
    "label_image(Reconstructions[-1][819], 'A')\n",
    "plt.axis('off')\n",
    "plt.subplot(232)\n",
    "markregion(Reconstructions[-1][2527], \n",
    "           (2230, 2093, 2527), 500, 500)\n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'].iloc[-1],'um'))\n",
    "label_image(Reconstructions[-1][819], 'B')\n",
    "plt.axis('off')\n",
    "plt.subplot(233)\n",
    "markregion(Reconstructions[-1][819], \n",
    "           (2061, 1878, 819), 500, 500)\n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'].iloc[-1],'um'))\n",
    "label_image(Reconstructions[-1][819], 'C')\n",
    "plt.axis('off')\n",
    "#---\n",
    "plt.subplot(234)\n",
    "plt.imshow(extract(Reconstructions[-1],\n",
    "                   (1936, 2218, 819), 500, 500))\n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'].iloc[-1],'um'))\n",
    "label_image(extract(Reconstructions[-1],\n",
    "                   (1936, 2218, 819), 500, 500),\n",
    "            'D')\n",
    "plt.axis('off')\n",
    "plt.subplot(235)\n",
    "plt.imshow(extract(Reconstructions[-1],\n",
    "                   (2230, 2093, 2527), 500, 500))\n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'].iloc[-1],'um'))\n",
    "label_image(extract(Reconstructions[-1],\n",
    "                   (2230, 2093, 2527), 500, 500),\n",
    "            'E')\n",
    "plt.axis('off')\n",
    "plt.subplot(236)\n",
    "plt.imshow(extract(Reconstructions[-1],\n",
    "                   (2061, 1878, 819), 500, 500))\n",
    "plt.gca().add_artist(ScaleBar(Data['Voxelsize'].iloc[-1],'um'))\n",
    "label_image(extract(Reconstructions[-1],\n",
    "                   (2061, 1878, 819), 500, 500),\n",
    "            'F')\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0.1)\n",
    "plt.savefig(os.path.join(OutPutDir, 'Fig02.png'),\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Saved all figures to %s' % OutPutDir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
